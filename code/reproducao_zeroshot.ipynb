{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import yaml\n",
    "import random\n",
    "import numpy as np\n",
    "import sys\n",
    "\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "\n",
    "sys.path.append('../utils')\n",
    "from dataset import ECG_TEXT_Dsataset\n",
    "from builder import ECGCLIP\n",
    "from utils import find_best_thresholds, metrics_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = yaml.load(open(\"config.yaml\", \"r\"), Loader=yaml.FullLoader)\n",
    "model_checkpoints_folder = '../checkpoints/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "random.seed(0)\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load CODEmel dataset!\n",
      "train size: 35995\n",
      "val size: 2006\n",
      "tst size: 1999\n",
      "total size: 40000\n",
      "Apply Val-stage Transform!\n",
      "val dataset length:  2006\n",
      "Apply Val-stage Transform!\n",
      "test dataset length:  1999\n"
     ]
    }
   ],
   "source": [
    "# data_path = config['dataset']['data_path']\n",
    "data_path = '\\\\Users\\katri\\Downloads\\git\\lesaude\\code\\CODEmel'\n",
    "dataset = ECG_TEXT_Dsataset(\n",
    "    data_path=data_path, dataset_name=config['dataset']['dataset_name'])\n",
    "# train_dataset = dataset.get_dataset(train_test='train')\n",
    "val_dataset = dataset.get_dataset(train_test='val')\n",
    "tst_dataset = dataset.get_dataset(train_test = 'test')\n",
    "batch_size = 4\n",
    "val_loader = DataLoader(val_dataset, batch_size = batch_size, shuffle=False, )\n",
    "tst_loader = DataLoader(tst_dataset, batch_size = batch_size, shuffle=False, )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# builder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ECGCLIP(config['network'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\katri\\AppData\\Local\\Temp\\ipykernel_18132\\2575387603.py:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  ckpt = torch.load(model_checkpoints_folder + config['wandb_name'] + f'_bestZeroShotAll_ckpt.pth', map_location='cpu')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = model.to(device).eval()\n",
    "ckpt = torch.load(model_checkpoints_folder + config['wandb_name'] + f'_bestZeroShotAll_ckpt.pth', map_location='cpu')\n",
    "model.load_state_dict(ckpt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# zeroshot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # text_normal = 'ritmo sinusal regular. sem desvio de eixo. onda p: amplitude e duracao normais. pri: duracao normal. qrs: duracao, eixo, morfologia e amplitude normais. st: sem supra ou infradesnivelamento. onda t: morfologia habitual. qtc: duracao normal. conclusao: 1- ecg dentro dos limites da normalidade. o tracado impresso corresponde a apenas um trecho do registro eletrocardiografico. este laudo foi elaborado utilizando-se todo o tracado disponivel no sistema.'\n",
    "# text_1davb = 'ritmo sinusal regular. sem desvio de eixo. onda p: amplitude e duracao normais. pri: duracao aumentadata >200 ms. qrs: duracao, eixo, morfologia e amplitude normais. st: sem supra ou infradesnivelamento. onda t: morfologia habitual. qtc: duracao normal. conclusao: 1- bloqueio atrioventricular de primeiro grau. o tracado impresso corresponde a apenas um trecho do registro eletrocardiografico. este laudo foi elaborado utilizando-se todo o tracado disponivel no sistema.'\n",
    "# text_rbbb = 'ritmo sinusal regular. sem desvio de eixo. onda p: amplitude e duracao normais. pri: duracao normal. qrs: eixo e amplitudes normais. duracao aumentada. morfologia brd. st e onda t: alteracoes secundarias ao brd. qtc: duracao normal. conclusao: 1- bloqueio de ramo direito. o tracado impresso corresponde a apenas um trecho do registro eletrocardiografico. este laudo foi elaborado utilizando-se todo o tracado disponivel no sistema.'\n",
    "# text_lbbb = 'ritmo sinusal regular. sem desvio de eixo. onda p: amplitude e duracao normais. pri: duracao normal. qrs: eixo e amplitudes normais. duracao aumentada. morfologia bre. st e onda t: alteracoes secundarias ao bre. qtc: duracao normal. conclusao: 1- bloqueio de ramo esquerdo. o tracado impresso corresponde a apenas um trecho do registro eletrocardiografico. este laudo foi elaborado utilizando-se todo o tracado disponivel no sistema.'\n",
    "# text_sb = 'ritmo sinusal regular com frequencia fc de bpm. sem desvio de eixo. onda p: amplitude e duracao normais. pri: duracao normal. qrs: duracao, eixo, morfologia e amplitude normais. st: sem supra ou infradesnivelamento. onda t: morfologia habitual. qtc: ms duracao normal. conclusao: 1- bradicardia sinusal (fc bpm). o tracado impresso corresponde a apenas um trecho do registro eletrocardiografico. este laudo foi elaborado utilizando-se todo o tracado disponivel no sistema.'\n",
    "# text_af = 'ritmo irregular. sem desvio de eixo. ausencia de onda p. pri: duracao normal. qrs: duracao, eixo, morfologia e amplitude normais. st: sem supra ou infradesnivelamento. onda t: morfologia habitual. qtc: duracao normal. conclusao: 1- fibrilacao atrial. o tracado impresso corresponde a apenas um trecho do registro eletrocardiografico. este laudo foi elaborado utilizando-se todo o tracado disponivel no sistema.'\n",
    "# text_st = 'ritmo sinusal regular com frequencia fc de bpm. sem desvio de eixo. onda p: amplitude e duracao normais. pri: duracao normal. qrs: duracao, eixo, morfologia e amplitude normais. st: sem supra ou infradesnivelamento. onda t: morfologia habitual. qtc: ms duracao normal. conclusao: 1- taquicardia sinusal (fc bpm). o tracado impresso corresponde a apenas um trecho do registro eletrocardiografico. este laudo foi elaborado utilizando-se todo o tracado disponivel no sistema.'\n",
    "\n",
    "# texts = [text_1davb, text_rbbb, text_lbbb, text_sb, text_af, text_st]\n",
    "# num_classes = len(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# eixos = ['Sem desvio de eixo.']\n",
    "# ondaps = ['Onda P: amplitude e duração normais.', \n",
    "#           'Onda P: ausente com R-R irregular.', 'AUSENCIA DE ONDA P.', ] # af\n",
    "# pris = ['PRi: duracao normal.', \n",
    "#         'PRi: duracao: >200ms.', 'PRI: DURACAO AUMENTADA (>200 MS).', ] # 1davb\n",
    "# qrss = ['QRS: DURACAO, EIXO, MORFOLOGIA E AMPLITUDE NORMAIS.', \n",
    "#         'QRS: DURACAO AUMENTADA, MORFOLOGIA DE BRD. AMPLITUDE NORMAL.', 'QRS: DURACAO AUMENTADA, MORFOLOGIA DE bloqueio do ramo direito. AMPLITUDE NORMAL.', 'QRS: Eixo e Amplitudes normais. Duracao aumentada e rsR em V1 e onda S empastada nas derivacoes a esquerda.', 'QRS: EIXO E AMPLITUDES NORMAIS. DURACAO AUMENTADA E RSR&APOS; EM V1 E ONDA S EMPASTADA NAS DERIVACOES A ESQUERDA.', 'QRS: Eixo e Amplitudes normais. Duracao (130 ms). Morfologia: BRD: rsR em V1 e onda S empastada nas derivacoes a esquerda.', # rbbb\n",
    "#         'QRS: MORFOLOGIA DE BRE. DURACAO AUMENTADA (150 MS).', 'QRS: com duração aumentada > 120 ms e morfologia de bloqueio do ramo esquerdo.', ] # lbbb\n",
    "# # sts = ['ST: SEM SUPRA OU INFRADESNIVELAMENTO.', \n",
    "# #        ]\n",
    "# # ondats = ['ONDA T: MORFOLOGIA HABITUAL.', \n",
    "# #           ]\n",
    "# stsandondats = ['ST e Onda T: normal.', 'ST: SEM SUPRA OU INFRADESNIVELAMENTO. ONDA T: MORFOLOGIA HABITUAL.'\n",
    "#                 'ST e Onda T: alteracoes secundarias ao BRD.', 'ST e Onda T: alteracoes secundarias ao bloqueio do ramo direito.', # rbbb\n",
    "#                 'ST e Onda T: alterações secundarias ao BRE.', 'ST e Onda T: alteracoes secundarias ao bloqueio do ramo esquerdo.'] # lbbb\n",
    "# qtcs = ['QTi: duracao normal.', 'QTc: duração normal.', \n",
    "#         'QTI: 370MS DURACAO NORMAL.', 'QTi: 434ms duracao normal.'] # sb\n",
    "# conclusoes = ['Conclusao: 1- Bloqueio atrioventricular de primeiro grau.', 'CONCLUSAO: 1- BLOQUEIO ATRIOVENTRICULAR 1 GRAU.', 'Conclusao: 1- Bloqueio AV de primeiro grau.', # 1davb\n",
    "#               'Conclusao: 1- Bloqueio de ramo direito.', # rbbb\n",
    "#               'Conclusao: 1- Bloqueio de ramo esquerdo.', # lbbb\n",
    "#               'CONCLUSAO: 1- BRADICARDIA SINUSAL (FC=49 BPM).', 'CONCLUSAO: 1- BRADICARDIA SINUSAL.', # sb\n",
    "#               'CONCLUSAO: 1- FIBRILACAO ATRIAL.', # af\n",
    "#               'Conclusao: 1- Taquicardia sinusal.', 'Conclusao: 1- Taquicardia Sinusal (FC= 103bpm)', ] # st"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "qtcs = ['QTi: duracao normal.', 'QTc: duração normal.']\n",
    "stsandondats = ['ST e Onda T: normal.', 'ST: SEM SUPRA OU INFRADESNIVELAMENTO. ONDA T: MORFOLOGIA HABITUAL.']\n",
    "\n",
    "# 1davb\n",
    "pris = ['PRi: duracao: >200ms.', 'PRI: DURACAO AUMENTADA (>200 MS).']\n",
    "conclusoes_1davb = ['Conclusao: 1- Bloqueio atrioventricular de primeiro grau.', 'CONCLUSAO: 1- BLOQUEIO ATRIOVENTRICULAR 1 GRAU.', 'Conclusao: 1- Bloqueio AV de primeiro grau.']\n",
    "\n",
    "# rbbb\n",
    "qrss_rbbb = ['QRS: DURACAO AUMENTADA, MORFOLOGIA DE BRD. AMPLITUDE NORMAL.', 'QRS: DURACAO AUMENTADA, MORFOLOGIA DE bloqueio do ramo direito. AMPLITUDE NORMAL.', 'QRS: Eixo e Amplitudes normais. Duracao aumentada e rsR em V1 e onda S empastada nas derivacoes a esquerda.', 'QRS: EIXO E AMPLITUDES NORMAIS. DURACAO AUMENTADA E RSR&APOS; EM V1 E ONDA S EMPASTADA NAS DERIVACOES A ESQUERDA.', 'QRS: Eixo e Amplitudes normais. Duracao (130 ms). Morfologia: BRD: rsR em V1 e onda S empastada nas derivacoes a esquerda.'] \n",
    "stsandondats_lbbb = ['ST e Onda T: alteracoes secundarias ao BRD.', 'ST e Onda T: alteracoes secundarias ao bloqueio do ramo direito.']\n",
    "\n",
    "# lbbb\n",
    "qrss_lbbb = ['QRS: MORFOLOGIA DE BRE. DURACAO AUMENTADA (150 MS).', 'QRS: com duração aumentada > 120 ms e morfologia de bloqueio do ramo esquerdo.']\n",
    "stsandondats_rbbb = ['ST e Onda T: alteracoes secundarias ao BRD.', 'ST e Onda T: alteracoes secundarias ao bloqueio do ramo direito.']\n",
    "\n",
    "# sb\n",
    "conclusoes_sb = ['CONCLUSAO: 1- BRADICARDIA SINUSAL (FC=49 BPM).', 'CONCLUSAO: 1- BRADICARDIA SINUSAL.']\n",
    "qtcs_sb = ['QTI: 370MS DURACAO NORMAL.', 'QTi: 434ms duracao normal.']\n",
    "\n",
    "# af\n",
    "ondaps = ['Onda P: ausente com R-R irregular.', 'AUSENCIA DE ONDA P.']\n",
    "\n",
    "# st\n",
    "conclusoes_st = ['Conclusao: 1- Taquicardia sinusal.', 'Conclusao: 1- Taquicardia Sinusal (FC= 103bpm)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_1davb = ['ritmo sinusal regular. sem desvio de eixo. onda p: amplitude e duracao normais. pri: duracao aumentadata >200 ms. qrs: duracao, eixo, morfologia e amplitude normais. st: sem supra ou infradesnivelamento. onda t: morfologia habitual. qtc: duracao normal. conclusao: 1- bloqueio atrioventricular de primeiro grau. o tracado impresso corresponde a apenas um trecho do registro eletrocardiografico. este laudo foi elaborado utilizando-se todo o tracado disponivel no sistema.']\n",
    "for pri in pris:\n",
    "    for standondat in stsandondats:\n",
    "        for qtc in qtcs:\n",
    "            for conclusao in conclusoes_1davb:\n",
    "                text_1davb.append(f'Ritmo sinusal regular. Sem desvio de eixo. {pri} QRS: DURACAO, EIXO, MORFOLOGIA E AMPLITUDE NORMAIS. {standondat} {qtc} {conclusao}')\n",
    "\n",
    "text_rbbb = ['ritmo sinusal regular. sem desvio de eixo. onda p: amplitude e duracao normais. pri: duracao normal. qrs: eixo e amplitudes normais. duracao aumentada. morfologia brd. st e onda t: alteracoes secundarias ao brd. qtc: duracao normal. conclusao: 1- bloqueio de ramo direito. o tracado impresso corresponde a apenas um trecho do registro eletrocardiografico. este laudo foi elaborado utilizando-se todo o tracado disponivel no sistema.']\n",
    "for qrs in qrss_rbbb:\n",
    "    for standondat in stsandondats_rbbb:\n",
    "        for qtc in qtcs:\n",
    "            text_rbbb.append(f'Ritmo sinusal regular. Sem desvio de eixo. Onda P: amplitude e duração normais. PRi: duracao normal. {qrs} {standondat} {qtc} Conclusao: 1- Bloqueio de ramo direito.')\n",
    "\n",
    "text_lbbb = ['ritmo sinusal regular. sem desvio de eixo. onda p: amplitude e duracao normais. pri: duracao normal. qrs: eixo e amplitudes normais. duracao aumentada. morfologia bre. st e onda t: alteracoes secundarias ao bre. qtc: duracao normal. conclusao: 1- bloqueio de ramo esquerdo. o tracado impresso corresponde a apenas um trecho do registro eletrocardiografico. este laudo foi elaborado utilizando-se todo o tracado disponivel no sistema.']\n",
    "for qrs in qrss_lbbb:\n",
    "    for standondat in stsandondats_lbbb:\n",
    "        for qtc in qtcs:\n",
    "            text_lbbb.append(f'Ritmo sinusal regular. Sem desvio de eixo. Onda P: amplitude e duração normais. PRi: duracao normal. {qrs} {standondat} {qtc} Conclusao: 1- Bloqueio de ramo esquerdo.')\n",
    "\n",
    "text_sb = ['ritmo sinusal regular com frequencia fc de bpm. sem desvio de eixo. onda p: amplitude e duracao normais. pri: duracao normal. qrs: duracao, eixo, morfologia e amplitude normais. st: sem supra ou infradesnivelamento. onda t: morfologia habitual. qtc: ms duracao normal. conclusao: 1- bradicardia sinusal (fc bpm). o tracado impresso corresponde a apenas um trecho do registro eletrocardiografico. este laudo foi elaborado utilizando-se todo o tracado disponivel no sistema.']\n",
    "for standondat in stsandondats:\n",
    "    for qtc in qtcs_sb:\n",
    "        for conclusao in conclusoes_sb:\n",
    "            text_sb.append(f'ritmo sinusal regular com frequencia fc de bpm. Sem desvio de eixo. Onda P: amplitude e duração normais. PRi: duracao normal. QRS: DURACAO, EIXO, MORFOLOGIA E AMPLITUDE NORMAIS. {standondat} {qtc} {conclusao}')\n",
    "\n",
    "text_af = ['ritmo irregular. sem desvio de eixo. ausencia de onda p. pri: duracao normal. qrs: duracao, eixo, morfologia e amplitude normais. st: sem supra ou infradesnivelamento. onda t: morfologia habitual. qtc: duracao normal. conclusao: 1- fibrilacao atrial. o tracado impresso corresponde a apenas um trecho do registro eletrocardiografico. este laudo foi elaborado utilizando-se todo o tracado disponivel no sistema.']\n",
    "for ondap in ondaps:\n",
    "    for standondat in stsandondats:\n",
    "        for qtc in qtcs:\n",
    "            text_af.append(f'Ritmo irregular. Sem desvio de eixo. {ondap} PRi: duracao normal. QRS: DURACAO, EIXO, MORFOLOGIA E AMPLITUDE NORMAIS. {standondat} {qtc} CONCLUSAO: 1- FIBRILACAO ATRIAL.')\n",
    "\n",
    "text_st = ['ritmo sinusal regular com frequencia fc de bpm. sem desvio de eixo. onda p: amplitude e duracao normais. pri: duracao normal. qrs: duracao, eixo, morfologia e amplitude normais. st: sem supra ou infradesnivelamento. onda t: morfologia habitual. qtc: ms duracao normal. conclusao: 1- taquicardia sinusal (fc bpm). o tracado impresso corresponde a apenas um trecho do registro eletrocardiografico. este laudo foi elaborado utilizando-se todo o tracado disponivel no sistema.']\n",
    "for standondat in stsandondats:\n",
    "    for qtc in qtcs_sb:\n",
    "        for conclusao in conclusoes_st:\n",
    "            text_st.append(f'ritmo sinusal regular com frequencia fc de bpm. Sem desvio de eixo. Onda P: amplitude e duração normais. PRi: duracao normal. QRS: DURACAO, EIXO, MORFOLOGIA E AMPLITUDE NORMAIS. {standondat} {qtc} {conclusao}')\n",
    "\n",
    "texts = text_1davb + text_rbbb + text_lbbb + text_sb + text_af + text_st\n",
    "num_classes = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre = 0\n",
    "pos = len(text_1davb)\n",
    "slice_1davb = slice(pre,pos)\n",
    "\n",
    "pre = pos\n",
    "pos += len(text_rbbb)\n",
    "slice_rbbb = slice(pre,pos)\n",
    "\n",
    "pre = pos\n",
    "pos += len(text_lbbb)\n",
    "slice_lbbb = slice(pre,pos)\n",
    "\n",
    "pre = pos\n",
    "pos += len(text_sb)\n",
    "slice_sb = slice(pre,pos)\n",
    "\n",
    "pre = pos\n",
    "pos += len(text_af)\n",
    "slice_af = slice(pre,pos)\n",
    "\n",
    "pre = pos\n",
    "pos += len(text_st)\n",
    "slice_st = slice(pre,pos)\n",
    "\n",
    "slices = [slice_1davb, slice_rbbb, slice_lbbb, slice_sb, slice_af, slice_st]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ecg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 82/82 [00:32<00:00,  2.52it/s]\n",
      "100%|██████████| 502/502 [01:07<00:00,  7.41it/s]\n",
      "100%|██████████| 500/500 [00:59<00:00,  8.45it/s]\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    # text synthesis\n",
    "    zeroshot_weights = []\n",
    "    for text in tqdm(texts):\n",
    "        text = model._tokenize([text.lower()])\n",
    "\n",
    "        class_embeddings = model.get_text_emb(text.input_ids.to(device=device), text.attention_mask.to(device=device)) # embed with text encoder\n",
    "        class_embeddings = model.proj_t(class_embeddings) # embed with text encoder\n",
    "\n",
    "        # normalize class_embeddings\n",
    "        class_embeddings /= class_embeddings.norm(dim=-1, keepdim=True)\n",
    "        # average over templates \n",
    "        class_embedding = class_embeddings.mean(dim=0) \n",
    "        # norm over new averaged templates\n",
    "        class_embedding /= class_embedding.norm()\n",
    "\n",
    "        zeroshot_weights.append(class_embedding)\n",
    "    zeroshot_weights = torch.stack(zeroshot_weights, dim=1)\n",
    "\n",
    "    # val thresholds\n",
    "    thresholds = np.arange(0, 1.01, 0.01)\n",
    "    predictions = {thresh: [[] for _ in range(num_classes)] for thresh in thresholds}\n",
    "    true_labels_dict = [[] for _ in range(num_classes)]\n",
    "    for data in tqdm(val_loader):\n",
    "        # read\n",
    "        # report = data['raw_text']\n",
    "        ecg = data['ecg'].to(torch.float32).to(device).contiguous()\n",
    "        label = data['label'].float().to(device)\n",
    "        exam_id = data['exam_id'].to(device)\n",
    "\n",
    "        # predict\n",
    "        ecg_emb = model.ext_ecg_emb(ecg)\n",
    "        ecg_emb /= ecg_emb.norm(dim=-1, keepdim=True)\n",
    "\n",
    "        # obtain logits (cos similarity)\n",
    "        logits = ecg_emb @ zeroshot_weights\n",
    "        logits = torch.squeeze(logits, 0) # (N, num_classes)\n",
    "        logits = torch.stack([torch.max(logits[:, s], axis = 1).values for s in slices]).T\n",
    "\n",
    "        # norm_logits = (logits - logits.mean()) / (logits.std())\n",
    "        # norm_logits = (logits - logits.mean(axis = 1).unsqueeze(1)) / (logits.std(axis = 1).unsqueeze(1))\n",
    "        # probs = torch.sigmoid(norm_logits)\n",
    "        probs = torch.sigmoid(logits)\n",
    "\n",
    "        for class_idx in range(num_classes):\n",
    "            for thresh in thresholds:\n",
    "                predicted_binary = (probs[:, class_idx] >= thresh).float()\n",
    "                predictions[thresh][class_idx].extend(predicted_binary.cpu().numpy())\n",
    "            true_labels_dict[class_idx].extend(label[:, class_idx].cpu().numpy())\n",
    "    best_f1s, best_thresholds = find_best_thresholds(predictions, true_labels_dict, thresholds)\n",
    "\n",
    "    # test\n",
    "    y_pred = []\n",
    "    all_binary_results = []\n",
    "    all_true_labels = []\n",
    "    for data in tqdm(tst_loader):\n",
    "        # read\n",
    "        # report = data['raw_text']\n",
    "        ecg = data['ecg'].to(torch.float32).to(device).contiguous()\n",
    "        label = data['label'].float().to(device)\n",
    "        exam_id = data['exam_id'].to(device)\n",
    "\n",
    "        # predict\n",
    "        ecg_emb = model.ext_ecg_emb(ecg)\n",
    "        ecg_emb /= ecg_emb.norm(dim=-1, keepdim=True)\n",
    "\n",
    "        # obtain logits (cos similarity)\n",
    "        logits = ecg_emb @ zeroshot_weights\n",
    "        logits = torch.squeeze(logits, 0) # (N, num_classes)\n",
    "        logits = torch.stack([torch.max(logits[:, s], axis = 1).values for s in slices]).T\n",
    "\n",
    "        # norm_logits = (logits - logits.mean()) / (logits.std())\n",
    "        # norm_logits = (logits - logits.mean(axis = 1).unsqueeze(1)) / (logits.std(axis = 1).unsqueeze(1))\n",
    "        # probs = torch.sigmoid(norm_logits)\n",
    "        probs = torch.sigmoid(logits)\n",
    "\n",
    "        binary_result = torch.zeros_like(probs)\n",
    "        for i in range(len(best_thresholds)):\n",
    "            binary_result[:, i] = (probs[:, i] >= best_thresholds[i]).float()\n",
    "\n",
    "        y_pred.append(logits)\n",
    "        all_binary_results.append(binary_result)\n",
    "        all_true_labels.append(label)\n",
    "        \n",
    "    y_pred = torch.cat(y_pred, dim=0)\n",
    "    all_binary_results = torch.cat(all_binary_results, dim=0)\n",
    "    all_true_labels = torch.cat(all_true_labels, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Accuracy': [0.832416208104052,\n",
       "  0.9719859929964982,\n",
       "  0.9899949974987494,\n",
       "  0.9874937468734367,\n",
       "  0.9779889944972486,\n",
       "  0.9469734867433717,\n",
       "  0.8589294647323662],\n",
       " 'F1 Score': [np.float64(0.09703504043126684),\n",
       "  np.float64(0.5882352941176471),\n",
       "  np.float64(0.7560975609756098),\n",
       "  np.float64(0.5454545454545454),\n",
       "  np.float64(0.26666666666666666),\n",
       "  np.float64(0.3614457831325301),\n",
       "  np.float64(0.9166173861620343)],\n",
       " 'AUC ROC': [np.float64(0.6451123021949975),\n",
       "  np.float64(0.8806065547368844),\n",
       "  np.float64(0.9153511309474612),\n",
       "  np.float64(0.7558288114825835),\n",
       "  np.float64(0.6130669061517737),\n",
       "  np.float64(0.8911954491424691),\n",
       "  np.float64(0.8324824249552272)]}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_table(all_binary_results, all_true_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 502/502 [13:23<00:00,  1.60s/it]\n",
      "100%|██████████| 500/500 [14:04<00:00,  1.69s/it]\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    # # text synthesis\n",
    "    # zeroshot_weights = []\n",
    "    # for text in tqdm(texts):\n",
    "    #     text = model._tokenize([text.lower()])\n",
    "\n",
    "    #     class_embeddings = model.get_text_emb(text.input_ids.to(device=device), text.attention_mask.to(device=device)) # embed with text encoder\n",
    "    #     class_embeddings = model.proj_t(class_embeddings) # embed with text encoder\n",
    "\n",
    "    #     # normalize class_embeddings\n",
    "    #     class_embeddings /= class_embeddings.norm(dim=-1, keepdim=True)\n",
    "    #     # average over templates \n",
    "    #     class_embedding = class_embeddings.mean(dim=0) \n",
    "    #     # norm over new averaged templates\n",
    "    #     class_embedding /= class_embedding.norm()\n",
    "\n",
    "    #     zeroshot_weights.append(class_embedding)\n",
    "    # zeroshot_weights = torch.stack(zeroshot_weights, dim=1)\n",
    "\n",
    "    # val thresholds\n",
    "    thresholds = np.arange(0, 1.01, 0.01)\n",
    "    predictions = {thresh: [[] for _ in range(num_classes)] for thresh in thresholds}\n",
    "    true_labels_dict = [[] for _ in range(num_classes)]\n",
    "    for data in tqdm(val_loader):\n",
    "        # read\n",
    "        report = data['raw_text']\n",
    "        # ecg = data['ecg'].to(torch.float32).to(device).contiguous()\n",
    "        label = data['label'].float().to(device)\n",
    "        exam_id = data['exam_id'].to(device)\n",
    "\n",
    "        # predict\n",
    "        text = model._tokenize(report)\n",
    "        class_embeddings = model.get_text_emb(text.input_ids.to(device=device), text.attention_mask.to(device=device)) # embed with text encoder\n",
    "        class_embeddings = model.proj_t(class_embeddings) # embed with text encoder\n",
    "\n",
    "        # normalize class_embeddings\n",
    "        class_embeddings /= class_embeddings.norm(dim=-1, keepdim=True)\n",
    "        # average over templates \n",
    "        class_embedding = class_embeddings\n",
    "        # norm over new averaged templates\n",
    "        class_embedding /= class_embedding.norm()\n",
    "\n",
    "        # obtain logits (cos similarity)\n",
    "        logits = class_embedding @ zeroshot_weights\n",
    "        logits = torch.squeeze(logits, 0) # (N, num_classes)\n",
    "        logits = torch.stack([torch.max(logits[:, s], axis = 1).values for s in slices]).T\n",
    "\n",
    "        # norm_logits = (logits - logits.mean()) / (logits.std())\n",
    "        norm_logits = (logits - logits.mean(axis = 1).unsqueeze(1)) / (logits.std(axis = 1).unsqueeze(1))\n",
    "        probs = torch.sigmoid(norm_logits)\n",
    "\n",
    "        for class_idx in range(num_classes):\n",
    "            for thresh in thresholds:\n",
    "                predicted_binary = (probs[:, class_idx] >= thresh).float()\n",
    "                predictions[thresh][class_idx].extend(predicted_binary.cpu().numpy())\n",
    "            true_labels_dict[class_idx].extend(label[:, class_idx].cpu().numpy())\n",
    "    best_f1s, best_thresholds = find_best_thresholds(predictions, true_labels_dict, thresholds)\n",
    "\n",
    "    # test\n",
    "    y_pred = []\n",
    "    all_binary_results = []\n",
    "    all_true_labels = []\n",
    "    for data in tqdm(tst_loader):\n",
    "        # read\n",
    "        report = data['raw_text']\n",
    "        # ecg = data['ecg'].to(torch.float32).to(device).contiguous()\n",
    "        label = data['label'].float().to(device)\n",
    "        exam_id = data['exam_id'].to(device)\n",
    "\n",
    "        # predict\n",
    "        text = model._tokenize(report)\n",
    "        class_embeddings = model.get_text_emb(text.input_ids.to(device=device), text.attention_mask.to(device=device)) # embed with text encoder\n",
    "        class_embeddings = model.proj_t(class_embeddings) # embed with text encoder\n",
    "\n",
    "        # normalize class_embeddings\n",
    "        class_embeddings /= class_embeddings.norm(dim=-1, keepdim=True)\n",
    "        # average over templates \n",
    "        class_embedding = class_embeddings\n",
    "        # norm over new averaged templates\n",
    "        class_embedding /= class_embedding.norm()\n",
    "\n",
    "        # obtain logits (cos similarity)\n",
    "        logits = class_embedding @ zeroshot_weights\n",
    "        logits = torch.squeeze(logits, 0) # (N, num_classes)\n",
    "        logits = torch.stack([torch.max(logits[:, s], axis = 1).values for s in slices]).T\n",
    "\n",
    "        # norm_logits = (logits - logits.mean()) / (logits.std())\n",
    "        norm_logits = (logits - logits.mean(axis = 1).unsqueeze(1)) / (logits.std(axis = 1).unsqueeze(1))\n",
    "        probs = torch.sigmoid(norm_logits)\n",
    "\n",
    "        binary_result = torch.zeros_like(probs)\n",
    "        for i in range(len(best_thresholds)):\n",
    "            binary_result[:, i] = (probs[:, i] >= best_thresholds[i]).float()\n",
    "\n",
    "        y_pred.append(logits)\n",
    "        all_binary_results.append(binary_result)\n",
    "        all_true_labels.append(label)\n",
    "        \n",
    "    y_pred = torch.cat(y_pred, dim=0)\n",
    "    all_binary_results = torch.cat(all_binary_results, dim=0)\n",
    "    all_true_labels = torch.cat(all_true_labels, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Accuracy': [0.8849424712356178,\n",
       "  0.9644822411205602,\n",
       "  0.950975487743872,\n",
       "  0.9829914957478739,\n",
       "  0.9479739869934968,\n",
       "  0.966983491745873,\n",
       "  0.8054027013506754],\n",
       " 'F1 Score': [np.float64(0.15441176470588236),\n",
       "  np.float64(0.5170068027210885),\n",
       "  np.float64(0.3287671232876712),\n",
       "  np.float64(0.48484848484848486),\n",
       "  np.float64(0.07142857142857142),\n",
       "  np.float64(0.43103448275862066),\n",
       "  np.float64(0.8810033649434078)],\n",
       " 'AUC ROC': [np.float64(0.7086459928534966),\n",
       "  np.float64(0.8576619559528124),\n",
       "  np.float64(0.8026627544976169),\n",
       "  np.float64(0.7705321197269386),\n",
       "  np.float64(0.5399940128723245),\n",
       "  np.float64(0.8332130525839135),\n",
       "  np.float64(0.8089332014648098)]}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_table(all_binary_results, all_true_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mel",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
