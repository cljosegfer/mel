{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import yaml\n",
    "import random\n",
    "import numpy as np\n",
    "import sys\n",
    "\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "\n",
    "sys.path.append('../utils')\n",
    "from dataset import ECG_TEXT_Dsataset\n",
    "from builder import ECGCLIP\n",
    "from utils import find_best_thresholds, metrics_table\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = yaml.load(open(\"config.yaml\", \"r\"), Loader=yaml.FullLoader)\n",
    "model_checkpoints_folder = '../checkpoints/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "random.seed(0)\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load CODEmel dataset!\n",
      "train size: 35995\n",
      "val size: 2006\n",
      "tst size: 1999\n",
      "total size: 40000\n",
      "Apply Val-stage Transform!\n",
      "val dataset length:  2006\n",
      "Apply Val-stage Transform!\n",
      "test dataset length:  1999\n"
     ]
    }
   ],
   "source": [
    "# data_path = config['dataset']['data_path']\n",
    "data_path = '\\\\Users\\katri\\Downloads\\git\\lesaude\\code\\CODEmel'\n",
    "dataset = ECG_TEXT_Dsataset(\n",
    "    data_path=data_path, dataset_name=config['dataset']['dataset_name'])\n",
    "# train_dataset = dataset.get_dataset(train_test='train')\n",
    "val_dataset = dataset.get_dataset(train_test='val')\n",
    "tst_dataset = dataset.get_dataset(train_test = 'test')\n",
    "batch_size = 4\n",
    "val_loader = DataLoader(val_dataset, batch_size = batch_size, shuffle=False, )\n",
    "tst_loader = DataLoader(tst_dataset, batch_size = batch_size, shuffle=False, )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# builder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ECGCLIP(config['network'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\katri\\AppData\\Local\\Temp\\ipykernel_14940\\2575387603.py:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  ckpt = torch.load(model_checkpoints_folder + config['wandb_name'] + f'_bestZeroShotAll_ckpt.pth', map_location='cpu')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = model.to(device).eval()\n",
    "ckpt = torch.load(model_checkpoints_folder + config['wandb_name'] + f'_bestZeroShotAll_ckpt.pth', map_location='cpu')\n",
    "model.load_state_dict(ckpt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# zeroshot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # text_normal = 'ritmo sinusal regular. sem desvio de eixo. onda p: amplitude e duracao normais. pri: duracao normal. qrs: duracao, eixo, morfologia e amplitude normais. st: sem supra ou infradesnivelamento. onda t: morfologia habitual. qtc: duracao normal. conclusao: 1- ecg dentro dos limites da normalidade. o tracado impresso corresponde a apenas um trecho do registro eletrocardiografico. este laudo foi elaborado utilizando-se todo o tracado disponivel no sistema.'\n",
    "# text_1davb = 'ritmo sinusal regular. sem desvio de eixo. onda p: amplitude e duracao normais. pri: duracao aumentadata >200 ms. qrs: duracao, eixo, morfologia e amplitude normais. st: sem supra ou infradesnivelamento. onda t: morfologia habitual. qtc: duracao normal. conclusao: 1- bloqueio atrioventricular de primeiro grau. o tracado impresso corresponde a apenas um trecho do registro eletrocardiografico. este laudo foi elaborado utilizando-se todo o tracado disponivel no sistema.'\n",
    "# text_rbbb = 'ritmo sinusal regular. sem desvio de eixo. onda p: amplitude e duracao normais. pri: duracao normal. qrs: eixo e amplitudes normais. duracao aumentada. morfologia brd. st e onda t: alteracoes secundarias ao brd. qtc: duracao normal. conclusao: 1- bloqueio de ramo direito. o tracado impresso corresponde a apenas um trecho do registro eletrocardiografico. este laudo foi elaborado utilizando-se todo o tracado disponivel no sistema.'\n",
    "# text_lbbb = 'ritmo sinusal regular. sem desvio de eixo. onda p: amplitude e duracao normais. pri: duracao normal. qrs: eixo e amplitudes normais. duracao aumentada. morfologia bre. st e onda t: alteracoes secundarias ao bre. qtc: duracao normal. conclusao: 1- bloqueio de ramo esquerdo. o tracado impresso corresponde a apenas um trecho do registro eletrocardiografico. este laudo foi elaborado utilizando-se todo o tracado disponivel no sistema.'\n",
    "# text_sb = 'ritmo sinusal regular com frequencia fc de bpm. sem desvio de eixo. onda p: amplitude e duracao normais. pri: duracao normal. qrs: duracao, eixo, morfologia e amplitude normais. st: sem supra ou infradesnivelamento. onda t: morfologia habitual. qtc: ms duracao normal. conclusao: 1- bradicardia sinusal (fc bpm). o tracado impresso corresponde a apenas um trecho do registro eletrocardiografico. este laudo foi elaborado utilizando-se todo o tracado disponivel no sistema.'\n",
    "# text_af = 'ritmo irregular. sem desvio de eixo. ausencia de onda p. pri: duracao normal. qrs: duracao, eixo, morfologia e amplitude normais. st: sem supra ou infradesnivelamento. onda t: morfologia habitual. qtc: duracao normal. conclusao: 1- fibrilacao atrial. o tracado impresso corresponde a apenas um trecho do registro eletrocardiografico. este laudo foi elaborado utilizando-se todo o tracado disponivel no sistema.'\n",
    "# text_st = 'ritmo sinusal regular com frequencia fc de bpm. sem desvio de eixo. onda p: amplitude e duracao normais. pri: duracao normal. qrs: duracao, eixo, morfologia e amplitude normais. st: sem supra ou infradesnivelamento. onda t: morfologia habitual. qtc: ms duracao normal. conclusao: 1- taquicardia sinusal (fc bpm). o tracado impresso corresponde a apenas um trecho do registro eletrocardiografico. este laudo foi elaborado utilizando-se todo o tracado disponivel no sistema.'\n",
    "\n",
    "# texts = [text_1davb, text_rbbb, text_lbbb, text_sb, text_af, text_st]\n",
    "# num_classes = len(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "ritmoondap_normal = 'ritmo sinusal regular. onda p: amplitude e duracao normais.'\n",
    "ritmoondap_af = 'ritmo irregular. ausencia de onda p.'\n",
    "\n",
    "pri_normal = 'pri: duracao normal.'\n",
    "pri_1davb = 'pri: duracao aumentadata >200 ms.'\n",
    "\n",
    "qrsstondat_normal = 'qrs: duracao, eixo, morfologia e amplitude normais. st: sem supra ou infradesnivelamento. onda t: morfologia habitual.'\n",
    "qrsstondat_rbbb = 'qrs: eixo e amplitudes normais. duracao aumentada. morfologia brd. st e onda t: alteracoes secundarias ao brd.'\n",
    "qrsstondat_lbbb = 'qrs: eixo e amplitudes normais. duracao aumentada. morfologia bre. st e onda t: alteracoes secundarias ao bre.'\n",
    "\n",
    "# texts = [ritmoondap_normal, ritmoondap_af]\n",
    "# texts = [ritmo_normal, ritmo_af]\n",
    "# texts = [ondap_normal, ondap_af]\n",
    "# texts = [pri_normal, pri_1davb]\n",
    "# texts = [qrs_normal, qrs_rbbb, qrs_lbbb]\n",
    "# texts = [stondat_normal, stondat_rbbb, stondat_lbbb]\n",
    "texts = [qrsstondat_normal, qrsstondat_rbbb, qrsstondat_lbbb]\n",
    "num_classes = len(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:02<00:00,  1.20it/s]\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    # text synthesis\n",
    "    zeroshot_weights = []\n",
    "    for text in tqdm(texts):\n",
    "        text = model._tokenize([text.lower()])\n",
    "\n",
    "        class_embeddings = model.get_text_emb(text.input_ids.to(device=device), text.attention_mask.to(device=device)) # embed with text encoder\n",
    "        class_embeddings = model.proj_t(class_embeddings) # embed with text encoder\n",
    "\n",
    "        # normalize class_embeddings\n",
    "        class_embeddings /= class_embeddings.norm(dim=-1, keepdim=True)\n",
    "        # average over templates \n",
    "        class_embedding = class_embeddings.mean(dim=0) \n",
    "        # norm over new averaged templates\n",
    "        class_embedding /= class_embedding.norm()\n",
    "\n",
    "        zeroshot_weights.append(class_embedding)\n",
    "    zeroshot_weights = torch.stack(zeroshot_weights, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 502/502 [01:01<00:00,  8.19it/s]\n"
     ]
    }
   ],
   "source": [
    "y_pred = []\n",
    "all_binary_results = []\n",
    "all_true_labels = []\n",
    "with torch.no_grad():\n",
    "    for data in tqdm(val_loader):\n",
    "        # read\n",
    "        # report = data['raw_text']\n",
    "        ecg = data['ecg'].to(torch.float32).to(device).contiguous()\n",
    "        label = data['label'].float().to(device)\n",
    "        exam_id = data['exam_id'].to(device)\n",
    "\n",
    "        # predict\n",
    "        ecg_emb = model.ext_ecg_emb(ecg)\n",
    "        ecg_emb /= ecg_emb.norm(dim=-1, keepdim=True)\n",
    "\n",
    "        # obtain logits (cos similarity)\n",
    "        logits = ecg_emb @ zeroshot_weights\n",
    "        logits = torch.squeeze(logits, 0) # (N, num_classes)\n",
    "        # logits = torch.stack([torch.max(logits[:, s], axis = 1).values for s in slices]).T\n",
    "\n",
    "        # norm_logits = (logits - logits.mean()) / (logits.std())\n",
    "        norm_logits = (logits - logits.mean(axis = 1).unsqueeze(1)) / (logits.std(axis = 1).unsqueeze(1))\n",
    "        probs = torch.sigmoid(norm_logits)\n",
    "        # probs = torch.sigmoid(logits)\n",
    "        # break\n",
    "\n",
    "        binary_result = torch.zeros_like(probs)\n",
    "        binary_result[np.arange(logits.shape[0]), torch.argmax(probs, axis = 1)] = 1\n",
    "\n",
    "        y_pred.append(probs)\n",
    "        all_binary_results.append(binary_result)\n",
    "        all_true_labels.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = torch.cat(y_pred, dim=0)\n",
    "all_binary_results = torch.cat(all_binary_results, dim=0)\n",
    "all_true_labels = torch.cat(all_true_labels, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# probs, data['raw_text'], label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        ...,\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.]])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_binary_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_true_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.32222222222222224)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# f1_score(all_true_labels[:, 4], all_binary_results[:, 1], zero_division=0) # af\n",
    "# f1_score(all_true_labels[:, 1], all_binary_results[:, 1], zero_division=0) # rbbb\n",
    "f1_score(all_true_labels[:, 2], all_binary_results[:, 2], zero_division=0) # lbbb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/502 [00:02<?, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    for data in tqdm(val_loader):\n",
    "            # read\n",
    "            report = data['raw_text']\n",
    "            # ecg = data['ecg'].to(torch.float32).to(device).contiguous()\n",
    "            label = data['label'].float().to(device)\n",
    "            exam_id = data['exam_id'].to(device)\n",
    "\n",
    "            # predict\n",
    "            text = model._tokenize(report)\n",
    "            class_embeddings = model.get_text_emb(text.input_ids.to(device=device), text.attention_mask.to(device=device)) # embed with text encoder\n",
    "            class_embeddings = model.proj_t(class_embeddings) # embed with text encoder\n",
    "\n",
    "            # normalize class_embeddings\n",
    "            class_embeddings /= class_embeddings.norm(dim=-1, keepdim=True)\n",
    "            # average over templates \n",
    "            class_embedding = class_embeddings\n",
    "            # norm over new averaged templates\n",
    "            class_embedding /= class_embedding.norm()\n",
    "\n",
    "            # obtain logits (cos similarity)\n",
    "            logits = class_embedding @ zeroshot_weights\n",
    "            logits = torch.squeeze(logits, 0) # (N, num_classes)\n",
    "            # logits = torch.stack([torch.max(logits[:, s], axis = 1).values for s in slices]).T\n",
    "\n",
    "            # norm_logits = (logits - logits.mean()) / (logits.std())\n",
    "            norm_logits = (logits - logits.mean(axis = 1).unsqueeze(1)) / (logits.std(axis = 1).unsqueeze(1))\n",
    "            probs = torch.sigmoid(norm_logits)\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0.2488, 0.6991, 0.5650],\n",
       "         [0.7601, 0.3709, 0.3486],\n",
       "         [0.7582, 0.3948, 0.3284],\n",
       "         [0.5568, 0.7040, 0.2508]]),\n",
       " ['Ritmo atrial ectópico. Extrassístoles supraventriculares isoladas. Extrassístoles ventriculares isoladas. Sem desvio de eixo elétrico. Onda P: baixa amplitude e morfologia de ritmo atrial ectópico em DII, DIII e aVF. PRi: duração normal. QRS: duração e morfologia normais. Baixa amplitude do complexo QRS de DI a aVF. ST: sem supra ou infradesnivelamento. Onda T: morfologia habitual. QTc: duração normal. Conclusão: 1- Ritmo atrial ectópico. 2- Extrassístoles supraventriculares isoladas. 3- Extrassístoles ventriculares isoladas. 4- Baixa voltagem do complexo QRS no plano frontal (efeito dielétrico). Dr. Otaviano da Silva Júnior',\n",
       "  'RITMO SINUSAL REGULAR COM FREQUENCIA CARDIACA NORMAL. SEM DESVIO DE EIXO ELETRICO. ONDA P: AMPLITUDE E DURACAO NORMAIS. PRI: DURACAO NORMAL. QRS: DURACAO, MORFOLOGIA E AMPLITUDE NORMAIS. ST: SEM SUPRA OU INFRADESNIVELAMENTO. ONDA T: MORFOLOGIA HABITUAL. QTC: DURACAO NORMAL. CONCLUSAO: 1- ECG DENTRO DOS LIMITES DA NORMALIDADE. OBS: O TRACADO IMPRESSO CORRESPONDE A APENAS UM TRECHO DO REGISTRO ELETROCARDIOGRAFICO. ESTE LAUDO FOI ELABORADO UTILIZANDO-SE TODO O TRACADO, DISPONIVEL NO SISTEMA. OTAVIANO DA SILVA JUNIOR .',\n",
       "  'SEM DESVIO DE EIXO. ONDA P: AMPLITUDE E DURACAO NORMAIS. PRI: DURACAO NORMAL. QRS: DURACAO, EIXO, MORFOLOGIA E AMPLITUDE NORMAIS. ST: SEM SUPRA OU INFRADESNIVELAMENTO. ONDA T: MORFOLOGIA HABITUAL. QTC: DURACAO NORMAL =412 MS CONCLUSAO: 1-RITMO SINUSAL FC= 83BPM 2-ECG DENTRO DOS LIMITES DA NORMALIDADE. O TRACADO IMPRESSO CORRESPONDE A APENAS UM TRECHO DO REGISTRO ELETROCARDIOGRAFICO. ESTE LAUDO FOI ELABORADO UTILIZANDO-SE TODO O TRACADO, DISPONIVEL NO SISTEMA.',\n",
       "  'RITMO SINUSAL REGULAR. SEM DESVIO DE EIXO. ONDA P: AMPLITUDE E DURACAO NORMAIS. PRI: DURACAO NORMAL. QRS: EIXO E AMPLITUDES NORMAIS. DURACAO (150 MS). MORFOLOGIA: BRD: RSR EM V1 E ONDA S EMPASTADA NAS DERIVACOES A ESQUERDA. ST E ONDA T: ALTERACOES SECUNDARIAS AO BRD QTI: DURACAO NORMAL. CONCLUSAO: 1- BLOQUEIO DE RAMO DIREITO DE 3 GRAU.'],\n",
       " tensor([[0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 1., 0., 0., 0., 0.]]))"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs, data['raw_text'], label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    # text synthesis\n",
    "    zeroshot_weights = []\n",
    "    for text in tqdm(texts):\n",
    "        text = model._tokenize([text.lower()])\n",
    "\n",
    "        class_embeddings = model.get_text_emb(text.input_ids.to(device=device), text.attention_mask.to(device=device)) # embed with text encoder\n",
    "        class_embeddings = model.proj_t(class_embeddings) # embed with text encoder\n",
    "\n",
    "        # normalize class_embeddings\n",
    "        class_embeddings /= class_embeddings.norm(dim=-1, keepdim=True)\n",
    "        # average over templates \n",
    "        class_embedding = class_embeddings.mean(dim=0) \n",
    "        # norm over new averaged templates\n",
    "        class_embedding /= class_embedding.norm()\n",
    "\n",
    "        zeroshot_weights.append(class_embedding)\n",
    "    zeroshot_weights = torch.stack(zeroshot_weights, dim=1)\n",
    "\n",
    "    # val thresholds\n",
    "    thresholds = np.arange(0, 1.01, 0.01)\n",
    "    predictions = {thresh: [[] for _ in range(num_classes)] for thresh in thresholds}\n",
    "    true_labels_dict = [[] for _ in range(num_classes)]\n",
    "    for data in tqdm(val_loader):\n",
    "        # read\n",
    "        # report = data['raw_text']\n",
    "        ecg = data['ecg'].to(torch.float32).to(device).contiguous()\n",
    "        label = data['label'].float().to(device)\n",
    "        exam_id = data['exam_id'].to(device)\n",
    "\n",
    "        # predict\n",
    "        ecg_emb = model.ext_ecg_emb(ecg)\n",
    "        ecg_emb /= ecg_emb.norm(dim=-1, keepdim=True)\n",
    "\n",
    "        # obtain logits (cos similarity)\n",
    "        logits = ecg_emb @ zeroshot_weights\n",
    "        logits = torch.squeeze(logits, 0) # (N, num_classes)\n",
    "        logits = torch.stack([torch.max(logits[:, s], axis = 1).values for s in slices]).T\n",
    "\n",
    "        # norm_logits = (logits - logits.mean()) / (logits.std())\n",
    "        norm_logits = (logits - logits.mean(axis = 1).unsqueeze(1)) / (logits.std(axis = 1).unsqueeze(1))\n",
    "        probs = torch.sigmoid(norm_logits)\n",
    "\n",
    "        for class_idx in range(num_classes):\n",
    "            for thresh in thresholds:\n",
    "                predicted_binary = (probs[:, class_idx] >= thresh).float()\n",
    "                predictions[thresh][class_idx].extend(predicted_binary.cpu().numpy())\n",
    "            true_labels_dict[class_idx].extend(label[:, class_idx].cpu().numpy())\n",
    "    best_f1s, best_thresholds = find_best_thresholds(predictions, true_labels_dict, thresholds)\n",
    "\n",
    "    # test\n",
    "    y_pred = []\n",
    "    all_binary_results = []\n",
    "    all_true_labels = []\n",
    "    for data in tqdm(tst_loader):\n",
    "        # read\n",
    "        # report = data['raw_text']\n",
    "        ecg = data['ecg'].to(torch.float32).to(device).contiguous()\n",
    "        label = data['label'].float().to(device)\n",
    "        exam_id = data['exam_id'].to(device)\n",
    "\n",
    "        # predict\n",
    "        ecg_emb = model.ext_ecg_emb(ecg)\n",
    "        ecg_emb /= ecg_emb.norm(dim=-1, keepdim=True)\n",
    "\n",
    "        # obtain logits (cos similarity)\n",
    "        logits = ecg_emb @ zeroshot_weights\n",
    "        logits = torch.squeeze(logits, 0) # (N, num_classes)\n",
    "        logits = torch.stack([torch.max(logits[:, s], axis = 1).values for s in slices]).T\n",
    "\n",
    "        # norm_logits = (logits - logits.mean()) / (logits.std())\n",
    "        norm_logits = (logits - logits.mean(axis = 1).unsqueeze(1)) / (logits.std(axis = 1).unsqueeze(1))\n",
    "        probs = torch.sigmoid(norm_logits)\n",
    "\n",
    "        binary_result = torch.zeros_like(probs)\n",
    "        for i in range(len(best_thresholds)):\n",
    "            binary_result[:, i] = (probs[:, i] >= best_thresholds[i]).float()\n",
    "\n",
    "        y_pred.append(logits)\n",
    "        all_binary_results.append(binary_result)\n",
    "        all_true_labels.append(label)\n",
    "        \n",
    "    y_pred = torch.cat(y_pred, dim=0)\n",
    "    all_binary_results = torch.cat(all_binary_results, dim=0)\n",
    "    all_true_labels = torch.cat(all_true_labels, dim=0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mel",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
