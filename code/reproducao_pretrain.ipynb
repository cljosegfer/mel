{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "# from torch.nn.parallel import DistributedDataParallel as DDP\n",
    "# import torch.multiprocessing as mp\n",
    "# import torch.distributed as dist\n",
    "import tempfile\n",
    "import os\n",
    "from torch import optim\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import yaml\n",
    "import sys\n",
    "sys.path.append(\"../utils\")\n",
    "# from utils_trainer import trainer_wBert\n",
    "from trainer import trainer_wBert\n",
    "# import utils_dataset\n",
    "from dataset import ECG_TEXT_Dsataset\n",
    "# import utils_builder\n",
    "from builder import ECGCLIP\n",
    "\n",
    "# import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.environ[\"TOKENIZERS_PARALLELISM\"] = \"true\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dist.init_process_group(\"nccl\")\n",
    "torch.cuda.empty_cache()\n",
    "# rank = dist.get_rank()\n",
    "\n",
    "# device_id = torch.cuda.device_count()\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = yaml.load(open(\"config.yaml\", \"r\"), Loader=yaml.FullLoader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "project=\"MERL_ICML\",\n",
    "name = config['wandb_name'],\n",
    "# Track hyperparameters and run metadata\n",
    "config_param={\n",
    "        \"learning_rate\": config['optimizer']['params']['lr'],\n",
    "        \"total_epochs\": config['trainer']['max_epochs'],\n",
    "        'weight_decay': config['optimizer']['params']['weight_decay'],\n",
    "        'ecg_model': config['network']['ecg_model'],\n",
    "        'text_model': config['network']['text_model'],\n",
    "        'batch_size': config['trainer']['batch_size'],\n",
    "        'val_zeroshot': 'all_sets',\n",
    "        'prompt_type': config['zeroshot']['prompt_type'],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run = wandb.init(project = project, name = name, config = config_param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(('vit_tiny_demo',), 0.001, 20, 1e-08, 'resnet18')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name, config_param['learning_rate'], config_param['total_epochs'], config_param['weight_decay'], config_param['ecg_model']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('pucpr/biobertpt-all', 128, 'all_sets', 'CKEPE')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config_param['text_model'], config_param['batch_size'], config_param['val_zeroshot'], config_param['prompt_type']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "random.seed(0)\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## utils dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\\\Users\\\\katri\\\\Downloads\\\\git\\\\lesaude\\\\code\\\\CODEmel'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path = config['dataset']['data_path']\n",
    "data_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load CODEmel dataset!\n",
      "train size: 35995\n",
      "val size: 2006\n",
      "tst size: 1999\n",
      "total size: 40000\n",
      "Apply Train-stage Transform!\n",
      "train dataset length:  35995\n",
      "Apply Val-stage Transform!\n",
      "val dataset length:  2006\n"
     ]
    }
   ],
   "source": [
    "dataset = ECG_TEXT_Dsataset(\n",
    "    data_path=data_path, dataset_name=config['dataset']['dataset_name'])\n",
    "train_dataset = dataset.get_dataset(train_test='train')\n",
    "val_dataset = dataset.get_dataset(train_test='val')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## utils builder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ECGCLIP(config['network'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "if config['network']['free_layers'] is not None:\n",
    "    for layer_idx in range(int(config['network']['free_layers'])):\n",
    "        for param in list(model.lm_model.encoder.layer[layer_idx].parameters()):\n",
    "            param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = model.to(device_id)\n",
    "# model = DDP(model, device_ids=[device_id], find_unused_parameters=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## utils trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.AdamW(\n",
    "    model.parameters(),\n",
    "    **config['optimizer']['params'],\n",
    "    betas=(0.9, 0.999)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = trainer_wBert(model=model, \n",
    "                        optimizer=optimizer,\n",
    "                        device=device,\n",
    "                        model_name=config['wandb_name'],\n",
    "                        **config['trainer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainer.train_w_TextEmb(train_dataset, val_dataset, config['zeroshot'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data.dataloader import DataLoader\n",
    "from torch.cuda.amp import autocast as autocast\n",
    "from torch.cuda.amp import GradScaler as GradScaler\n",
    "from tqdm import tqdm\n",
    "\n",
    "from utils_loss import clip_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=trainer.train_batch_size,\n",
    "                            # num_workers=trainer.num_workers,\n",
    "                            drop_last=True, shuffle=False,\n",
    "                        #   sampler=DistributedSampler(train_dataset), \n",
    "                            )\n",
    "\n",
    "val_loader = DataLoader(val_dataset, batch_size=trainer.val_batch_size,\n",
    "                        # num_workers=trainer.num_workers,\n",
    "                        drop_last=True, shuffle=False,\n",
    "                        # sampler=DistributedSampler(val_dataset), \n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "directory \"../checkpoints/\" existing for save checkpoint!\n"
     ]
    }
   ],
   "source": [
    "model_checkpoints_folder = os.path.join('../checkpoints/')\n",
    "# if self.device == 0:\n",
    "if not os.path.exists(model_checkpoints_folder):\n",
    "    print('create directory \"{}\" for save checkpoint!'.format(\n",
    "        model_checkpoints_folder))\n",
    "    print('---------------------------')\n",
    "    os.makedirs(model_checkpoints_folder)\n",
    "else:\n",
    "    print('directory \"{}\" existing for save checkpoint!'.format(\n",
    "        model_checkpoints_folder))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#########################################\n",
      "Be patient..., checking checkpoint now...\n",
      "Start training from 0 epoch\n",
      "#########################################\n",
      "training start!\n"
     ]
    }
   ],
   "source": [
    "# automatically resume from checkpoint if it exists\n",
    "print('#########################################')\n",
    "print('Be patient..., checking checkpoint now...')\n",
    "if os.path.exists(model_checkpoints_folder + trainer.model_name+'_checkpoint.pth'):\n",
    "    ckpt = torch.load(model_checkpoints_folder + trainer.model_name+'_checkpoint.pth',\n",
    "                        map_location='cpu')\n",
    "    start_epoch = ckpt['epoch']\n",
    "    trainer.model.load_state_dict(ckpt['model_state_dict'])\n",
    "    trainer.optimizer.load_state_dict(ckpt['optimizer_state_dict'])\n",
    "    print('continue training successful!')\n",
    "else:\n",
    "    start_epoch = 0\n",
    "    print('Start training from 0 epoch')\n",
    "\n",
    "print('#########################################')\n",
    "print('training start!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scheduler\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(\n",
    "    trainer.optimizer,\n",
    "    T_0=5000,\n",
    "    T_mult=1,\n",
    "    eta_min=1e-8,\n",
    ")\n",
    "niter = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\katri\\AppData\\Local\\Temp\\ipykernel_10496\\1172279220.py:2: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = GradScaler()\n",
      "c:\\Users\\katri\\miniconda3\\envs\\mel\\lib\\site-packages\\torch\\amp\\grad_scaler.py:132: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "skip_scheduler = False\n",
    "scaler = GradScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_total = []\n",
    "acc_total = []\n",
    "auc_total = []\n",
    "zeroshot_csv = pd.DataFrame()\n",
    "best_auc = 0\n",
    "for epoch_counter in (range(start_epoch, trainer.max_epochs)):\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/281 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/281 [00:00<?, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "epoch_loss = 0\n",
    "epoch_acc1 = []\n",
    "epoch_acc5 = []\n",
    "# self.model.train()\n",
    "for data in tqdm(train_loader):\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.model.train()\n",
    "# get raw text\n",
    "report = data['raw_text']\n",
    "# get ecg\n",
    "ecg = data['ecg'].to(torch.float32).to(\n",
    "    trainer.device).contiguous()\n",
    "trainer.optimizer.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "report_tokenize_output = trainer.model._tokenize(report)\n",
    "\n",
    "input_ids = report_tokenize_output.input_ids.to(\n",
    "    trainer.device).contiguous()\n",
    "attention_mask = report_tokenize_output.attention_mask.to(\n",
    "    trainer.device).contiguous()\n",
    "\n",
    "output_dict = trainer.model(ecg, input_ids, attention_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_proj_img_emb = output_dict['proj_ecg_emb']\n",
    "agg_proj_text_emb = output_dict['proj_text_emb']\n",
    "agg_proj_ecg_emb1, agg_proj_ecg_emb2 = output_dict['ecg_emb']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_proj_img_emb = torch.cat(agg_proj_img_emb, dim=0)\n",
    "agg_proj_text_emb = torch.cat(agg_proj_text_emb, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "cma_loss, acc1, acc5 = clip_loss(agg_proj_img_emb, agg_proj_text_emb, device=trainer.device)\n",
    "uma_loss, _, _ = clip_loss(agg_proj_ecg_emb1, agg_proj_ecg_emb2, device=trainer.device)\n",
    "loss = cma_loss + uma_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss is 20.105636596679688, acc1 is 0.78125, acc5 is 3.515625, cma_loss is 10.219921112060547, uma_loss is 9.885714530944824\n"
     ]
    }
   ],
   "source": [
    "print(f'loss is {loss.item()}, acc1 is {acc1.item()}, acc5 is {acc5.item()}, cma_loss is {cma_loss.item()}, uma_loss is {uma_loss.item()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch_loss += loss.item()\n",
    "epoch_acc1.append(acc1.item())\n",
    "epoch_acc5.append(acc5.item())\n",
    "\n",
    "scaler.scale(loss).backward()\n",
    "scaler.step(trainer.optimizer)\n",
    "scaler.update()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not skip_scheduler:\n",
    "    scheduler.step()\n",
    "niter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# val_log = trainer.val(val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mel",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
