{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import yaml\n",
    "import random\n",
    "import numpy as np\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "\n",
    "sys.path.append('../utils')\n",
    "# from dataset import ECG_TEXT_Dsataset\n",
    "from dataset import ECG_test_Dsataset\n",
    "from builder import ECGCLIP\n",
    "from utils import find_best_thresholds, metrics_table\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../checkpoints/vit_tiny_150_bestZeroShotAll_ckpt.pth'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = yaml.load(open(\"config.yaml\", \"r\"), Loader=yaml.FullLoader)\n",
    "model_checkpoints_folder = '../checkpoints/'\n",
    "model_checkpoints_folder + config['wandb_name'] + f'_bestZeroShotAll_ckpt.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "random.seed(0)\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'CODEmel'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config['dataset']['dataset_name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load CODEtestmel dataset!\n",
      "Apply Val-stage Transform!\n",
      "code test dataset length:  827\n"
     ]
    }
   ],
   "source": [
    "# data_path = config['dataset']['data_path']\n",
    "data_path = 'D:\\datasets\\codetest-mel'\n",
    "dataset = ECG_test_Dsataset(\n",
    "    data_path=data_path, dataset_name='CODEtestmel')\n",
    "tst_dataset = dataset.get_dataset()\n",
    "batch_size = 4\n",
    "tst_loader = DataLoader(tst_dataset, batch_size = batch_size, shuffle=False, )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# builder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ECGCLIP(config['network'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = model.to(device).eval()\n",
    "ckpt = torch.load(model_checkpoints_folder + config['wandb_name'] + f'_bestZeroShotAll_ckpt.pth', map_location='cpu')\n",
    "model.load_state_dict(ckpt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# zeroshot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## subfeatures com normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_1davb = 'bloqueio atrioventricular de primeiro grau'\n",
    "text_rbbb = 'bloqueio de ramo direito'\n",
    "text_lbbb = 'bloqueio de ramo esquerdo'\n",
    "text_sb = 'bradicardia'\n",
    "text_af = 'fibrilacao atrial'\n",
    "text_st = 'taquicardia'\n",
    "text_normal = 'dentro dos limites da normalidade'\n",
    "\n",
    "texts = [text_1davb, text_rbbb, text_lbbb, text_sb, text_af, text_st, text_normal]\n",
    "num_classes = len(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:01<00:00,  6.12it/s]\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    # text synthesis\n",
    "    zeroshot_weights = []\n",
    "    for text in tqdm(texts):\n",
    "        text = model._tokenize([text.lower()])\n",
    "\n",
    "        class_embeddings = model.get_text_emb(text.input_ids.to(device=device), text.attention_mask.to(device=device)) # embed with text encoder\n",
    "        class_embeddings = model.proj_t(class_embeddings) # embed with text encoder\n",
    "\n",
    "        # normalize class_embeddings\n",
    "        class_embeddings /= class_embeddings.norm(dim=-1, keepdim=True)\n",
    "        # average over templates \n",
    "        class_embedding = class_embeddings.mean(dim=0) \n",
    "        # norm over new averaged templates\n",
    "        class_embedding /= class_embedding.norm()\n",
    "\n",
    "        zeroshot_weights.append(class_embedding)\n",
    "    zeroshot_weights = torch.stack(zeroshot_weights, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 207/207 [00:05<00:00, 36.08it/s]\n"
     ]
    }
   ],
   "source": [
    "y_pred = []\n",
    "all_binary_results = []\n",
    "all_true_labels = []\n",
    "with torch.no_grad():\n",
    "    for data in tqdm(tst_loader):\n",
    "        # read\n",
    "        # report = data['raw_text']\n",
    "        ecg = data['ecg'].to(torch.float32).to(device).contiguous()\n",
    "        label = data['label'].float().to(device)\n",
    "        exam_id = data['exam_id'].to(device)\n",
    "\n",
    "        # predict\n",
    "        ecg_emb = model.ext_ecg_emb(ecg)\n",
    "        ecg_emb /= ecg_emb.norm(dim=-1, keepdim=True)\n",
    "\n",
    "        # obtain logits (cos similarity)\n",
    "        logits = ecg_emb @ zeroshot_weights\n",
    "        logits = torch.squeeze(logits, 0) # (N, num_classes)\n",
    "        # logits = torch.stack([torch.max(logits[:, s], axis = 1).values for s in slices]).T\n",
    "\n",
    "        # norm_logits = (logits - logits.mean()) / (logits.std())\n",
    "        norm_logits = (logits - logits.mean(axis = 1).unsqueeze(1)) / (logits.std(axis = 1).unsqueeze(1))\n",
    "        probs = torch.sigmoid(norm_logits)\n",
    "        # probs = torch.sigmoid(logits)\n",
    "        # break\n",
    "\n",
    "        # binary_result = torch.zeros_like(probs)\n",
    "        # binary_result[np.arange(logits.shape[0]), torch.argmax(probs, axis = 1)] = 1\n",
    "\n",
    "        y_pred.append(probs)\n",
    "        # all_binary_results.append(binary_result)\n",
    "        all_true_labels.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = torch.cat(y_pred, dim=0)\n",
    "all_true_labels = torch.cat(all_true_labels, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0.4923, 0.6153, 0.5409,  ..., 0.7455, 0.7085, 0.1429],\n",
       "         [0.7836, 0.6682, 0.6465,  ..., 0.5407, 0.4025, 0.1554],\n",
       "         [0.3964, 0.2589, 0.2234,  ..., 0.7774, 0.7741, 0.4875],\n",
       "         ...,\n",
       "         [0.4070, 0.2288, 0.1957,  ..., 0.7310, 0.6712, 0.6879],\n",
       "         [0.3867, 0.2291, 0.2027,  ..., 0.6376, 0.6541, 0.6963],\n",
       "         [0.5459, 0.2012, 0.1851,  ..., 0.6903, 0.6770, 0.6082]]),\n",
       " tensor([[0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 1., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [1., 0., 0., 0., 0., 0.]]))"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred, all_true_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(np.float64(0.8006971951127358),\n",
       " [np.float64(0.6259610227069551),\n",
       "  np.float64(0.8560195831169795),\n",
       "  np.float64(0.8749477206189878),\n",
       "  np.float64(0.7997842170160295),\n",
       "  np.float64(0.7418257418257419),\n",
       "  np.float64(0.9056448853917209)])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log = []\n",
    "for i in range(6):\n",
    "    log.append(roc_auc_score(all_true_labels[:, i], y_pred[:, i]))\n",
    "np.mean(log), log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## subfeatures sem normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_1davb = 'bloqueio atrioventricular de primeiro grau'\n",
    "text_rbbb = 'bloqueio de ramo direito'\n",
    "text_lbbb = 'bloqueio de ramo esquerdo'\n",
    "text_sb = 'bradicardia'\n",
    "text_af = 'fibrilacao atrial'\n",
    "text_st = 'taquicardia'\n",
    "\n",
    "texts = [text_1davb, text_rbbb, text_lbbb, text_sb, text_af, text_st, ]\n",
    "num_classes = len(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:00<00:00,  6.01it/s]\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    # text synthesis\n",
    "    zeroshot_weights = []\n",
    "    for text in tqdm(texts):\n",
    "        text = model._tokenize([text.lower()])\n",
    "\n",
    "        class_embeddings = model.get_text_emb(text.input_ids.to(device=device), text.attention_mask.to(device=device)) # embed with text encoder\n",
    "        class_embeddings = model.proj_t(class_embeddings) # embed with text encoder\n",
    "\n",
    "        # normalize class_embeddings\n",
    "        class_embeddings /= class_embeddings.norm(dim=-1, keepdim=True)\n",
    "        # average over templates \n",
    "        class_embedding = class_embeddings.mean(dim=0) \n",
    "        # norm over new averaged templates\n",
    "        class_embedding /= class_embedding.norm()\n",
    "\n",
    "        zeroshot_weights.append(class_embedding)\n",
    "    zeroshot_weights = torch.stack(zeroshot_weights, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 207/207 [00:05<00:00, 34.97it/s]\n"
     ]
    }
   ],
   "source": [
    "y_pred = []\n",
    "all_binary_results = []\n",
    "all_true_labels = []\n",
    "with torch.no_grad():\n",
    "    for data in tqdm(tst_loader):\n",
    "        # read\n",
    "        # report = data['raw_text']\n",
    "        ecg = data['ecg'].to(torch.float32).to(device).contiguous()\n",
    "        label = data['label'].float().to(device)\n",
    "        exam_id = data['exam_id'].to(device)\n",
    "\n",
    "        # predict\n",
    "        ecg_emb = model.ext_ecg_emb(ecg)\n",
    "        ecg_emb /= ecg_emb.norm(dim=-1, keepdim=True)\n",
    "\n",
    "        # obtain logits (cos similarity)\n",
    "        logits = ecg_emb @ zeroshot_weights\n",
    "        logits = torch.squeeze(logits, 0) # (N, num_classes)\n",
    "        # logits = torch.stack([torch.max(logits[:, s], axis = 1).values for s in slices]).T\n",
    "\n",
    "        # norm_logits = (logits - logits.mean()) / (logits.std())\n",
    "        norm_logits = (logits - logits.mean(axis = 1).unsqueeze(1)) / (logits.std(axis = 1).unsqueeze(1))\n",
    "        probs = torch.sigmoid(norm_logits)\n",
    "        # probs = torch.sigmoid(logits)\n",
    "        # break\n",
    "\n",
    "        # binary_result = torch.zeros_like(probs)\n",
    "        # binary_result[np.arange(logits.shape[0]), torch.argmax(probs, axis = 1)] = 1\n",
    "\n",
    "        y_pred.append(probs)\n",
    "        # all_binary_results.append(binary_result)\n",
    "        all_true_labels.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = torch.cat(y_pred, dim=0)\n",
    "all_true_labels = torch.cat(all_true_labels, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(np.float64(0.7833614639218197),\n",
       " [np.float64(0.618138744859646),\n",
       "  np.float64(0.8715970625324532),\n",
       "  np.float64(0.8800920117105814),\n",
       "  np.float64(0.7452990135635018),\n",
       "  np.float64(0.7067662067662068),\n",
       "  np.float64(0.878275744098529)])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log = []\n",
    "for i in range(6):\n",
    "    log.append(roc_auc_score(all_true_labels[:, i], y_pred[:, i]))\n",
    "np.mean(log), log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# label vs 6x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_1davb = 'bloqueio atrioventricular de primeiro grau'\n",
    "text_rbbb = 'bloqueio de ramo direito'\n",
    "text_lbbb = 'bloqueio de ramo esquerdo'\n",
    "text_sb = 'bradicardia'\n",
    "text_af = 'fibrilacao atrial'\n",
    "text_st = 'taquicardia'\n",
    "\n",
    "texts = [text_1davb, text_rbbb, text_lbbb, text_sb, text_af, text_st, ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run6x(text_label, ):\n",
    "    text_normal = 'ecg dentro dos limites da normalidade'\n",
    "    texts = [text_label, text_normal]\n",
    "    num_classes = len(texts)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        # text synthesis\n",
    "        zeroshot_weights = []\n",
    "        for text in tqdm(texts):\n",
    "            text = model._tokenize([text.lower()])\n",
    "\n",
    "            class_embeddings = model.get_text_emb(text.input_ids.to(device=device), text.attention_mask.to(device=device)) # embed with text encoder\n",
    "            class_embeddings = model.proj_t(class_embeddings) # embed with text encoder\n",
    "\n",
    "            # normalize class_embeddings\n",
    "            class_embeddings /= class_embeddings.norm(dim=-1, keepdim=True)\n",
    "            # average over templates \n",
    "            class_embedding = class_embeddings.mean(dim=0) \n",
    "            # norm over new averaged templates\n",
    "            class_embedding /= class_embedding.norm()\n",
    "\n",
    "            zeroshot_weights.append(class_embedding)\n",
    "        zeroshot_weights = torch.stack(zeroshot_weights, dim=1)\n",
    "    \n",
    "    y_pred = []\n",
    "    all_true_labels = []\n",
    "    with torch.no_grad():\n",
    "        for data in tqdm(tst_loader):\n",
    "            # read\n",
    "            # report = data['raw_text']\n",
    "            ecg = data['ecg'].to(torch.float32).to(device).contiguous()\n",
    "            label = data['label'].float().to(device)\n",
    "            exam_id = data['exam_id'].to(device)\n",
    "\n",
    "            # predict\n",
    "            ecg_emb = model.ext_ecg_emb(ecg)\n",
    "            ecg_emb /= ecg_emb.norm(dim=-1, keepdim=True)\n",
    "\n",
    "            # obtain logits (cos similarity)\n",
    "            logits = ecg_emb @ zeroshot_weights\n",
    "            logits = torch.squeeze(logits, 0) # (N, num_classes)\n",
    "            # logits = torch.stack([torch.max(logits[:, s], axis = 1).values for s in slices]).T\n",
    "\n",
    "            # norm_logits = (logits - logits.mean()) / (logits.std())\n",
    "            norm_logits = (logits - logits.mean(axis = 1).unsqueeze(1)) / (logits.std(axis = 1).unsqueeze(1))\n",
    "            probs = torch.sigmoid(norm_logits)\n",
    "            # probs = torch.sigmoid(logits)\n",
    "            # break\n",
    "\n",
    "            # binary_result = torch.zeros_like(probs)\n",
    "            # binary_result[np.arange(logits.shape[0]), torch.argmax(probs, axis = 1)] = 1\n",
    "\n",
    "            y_pred.append(probs)\n",
    "            # all_binary_results.append(binary_result)\n",
    "            all_true_labels.append(label)\n",
    "    \n",
    "    y_pred = torch.cat(y_pred, dim=0)\n",
    "    all_true_labels = torch.cat(all_true_labels, dim=0)\n",
    "    \n",
    "    return roc_auc_score(all_true_labels[:, 0], y_pred[:, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00,  5.72it/s]\n",
      "100%|██████████| 207/207 [00:05<00:00, 35.81it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00,  6.54it/s]\n",
      "100%|██████████| 207/207 [00:05<00:00, 34.94it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00,  6.10it/s]\n",
      "100%|██████████| 207/207 [00:06<00:00, 32.96it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00,  6.51it/s]\n",
      "100%|██████████| 207/207 [00:05<00:00, 35.75it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00,  6.45it/s]\n",
      "100%|██████████| 207/207 [00:05<00:00, 35.75it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00,  6.25it/s]\n",
      "100%|██████████| 207/207 [00:05<00:00, 35.12it/s]\n"
     ]
    }
   ],
   "source": [
    "log = []\n",
    "for text_label in texts:\n",
    "    auc = run6x(text_label)\n",
    "    log.append(auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(np.float64(0.5671374932951905),\n",
       " [np.float64(0.5427319864115858),\n",
       "  np.float64(0.5818210262828535),\n",
       "  np.float64(0.5807482567495085),\n",
       "  np.float64(0.6614071160379045),\n",
       "  np.float64(0.547939388521366),\n",
       "  np.float64(0.4881771857679242)])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(log), log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mimicbaseline",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
